---

host_groups:
  group0: [server0]
  group1: [server1]
  group2: [server2]

group_services:
  group0: [AMBARI_SERVER, NAMENODE, ZKFC, HIVE_METASTORE, SPARK_THRIFTSERVER,FLINK_HISTORYSERVER,HISTORYSERVER,RANGER_TAGSYNC, RANGER_USERSYNC,ZOOKEEPER_SERVER,JOURNALNODE]
  group1: [APP_TIMELINE_SERVER, RANGER_ADMIN,NAMENODE, METRICS_GRAFANA,ZKFC, HBASE_MASTER, ZOOKEEPER_SERVER, DATANODE, NODEMANAGER, RESOURCEMANAGER, SPARK_JOBHISTORYSERVER, INFRA_SOLR, JOURNALNODE,KAFKA_BROKER]
  group2: [TIMELINE_READER,YARN_REGISTRY_DNS,METRICS_COLLECTOR, RESOURCEMANAGER, HBASE_REGIONSERVER, ZOOKEEPER_SERVER, DATANODE, NODEMANAGER,HIVE_SERVER, JOURNALNODE,WEBHCAT_SERVER,KAFKA_BROKER]


default_password: 'AsdQwe123456'                          # a default password for all required passwords which are not specified in the blueprint,

###########################
## cluster configuration ##
###########################
cluster_name: 'mytestcluster'
hdfs_ha_name: 'mytestcluster'

#Plugin: Executing Custom Operations Before Cluster Installation
plugins:
  - nexus_install_plugin: {enabled: false} #nexus Plugin:If enabled, a Nexus repository will be installed on the script machine before cluster installation.


#If nexus_install_plugin is set to false, the corresponding YUM repository will not be automatically installed. You will need to configure the desired repository address in the repos configuration.
repos:
   - {name: "ambari_repo", url: "http://server0:8081/repository/yum/sdp_3.1"}
   - {name: "os_base_repo", url: "http://server0:8081/repository/centos/7/os/x86_64"}
backup_old_repo: no                 #Whether to backup the old YUM repositories to /etc/yum.repos.d/bak, and then remove the old repositories, keeping only the repositories configured in this configuration.

packages_need_install: []

external_ntp_server_hostname: ''                     # if this is empty, ntp server will install and prepare on the ambari-server node

data_dirs: ["/data/sdv1"]


###########################
## general configuration ##
###########################

external_dns: yes                                         # set to yes to use the existing DNS (when no, it will update the /etc/hosts file - must be set to 'no' when using Azure)
disable_firewall: yes                                      # set to yes to disable the existing local firewall service (iptables, firewalld, ufw)
timezone: Asia/Shanghai

registry_dns_bind_port: "53"
blueprint_name: 'my_blueprint'         # the name of the blueprint as it will be stored in Ambari
############################
## database configuration ##
############################
#如果使用了外部数据库，需要手动创建对应的ambari 和 hive 还有ranger的用户，数据库
database: 'postgres'                                      # can be set to  'postgres', 'mysql'
postgres_port: 5432
mysql_port: 3306
database_options:
  repo_url: ''
  external_hostname: ''                                   # if this is empty, Ansible will install and prepare the databases on the ambari-server node
  ambari_db_name: 'ambari'
  ambari_db_username: 'ambari'
  ambari_db_password: 'bigdata'
  hive_db_name: 'hive'
  hive_db_username: 'hive'
  hive_db_password: 'hive'
  rangeradmin_db_name: 'ranger'
  rangeradmin_db_username: 'ranger'
  rangeradmin_db_password: 'ranger'
  rangerkms_db_name: 'rangerkms'
  rangerkms_db_username: 'rangerkms'
  rangerkms_db_password: 'rangerkms'


#####################################
## kerberos security configuration ##
#####################################

security: 'none'                                         # can be set to 'none', 'mit-kdc'
security_options:
  external_hostname: ''                                   # if this is empty, Ansible will install and prepare the MIT KDC on the Ambari node
  external_hostip: ''                                      # used to config /etc/hosts dns look up
  realm: 'MY-REALM.COM'
  admin_principal: 'admin/admin'                          # the Kerberos principal that has the permissions to create new users (don't append the realm)
  admin_password: "{{ default_password }}"
  kdc_master_key: "{{ default_password }}"                # only used when security is set to 'mit-kdc'
  http_authentication: yes                                # set to yes to enable HTTP authentication (SPNEGO)
  manage_krb5_conf: yes                                   # set to no if using FreeIPA/IdM

##########################
## ranger configuration ##                                # only useful if blueprint is dynamic
##########################

ranger_options:                                           # only used if RANGER_ADMIN is part of the blueprint stack
  enable_plugins: no                                     # set to 'yes' if the plugins should be enabled for all of the installed services

ranger_security_options:                                  # only used if RANGER_ADMIN is part of the blueprint stack
  ranger_admin_password: "{{ default_password }}"         # the password for the Ranger admin users (both admin and amb_ranger_admin)
  ranger_keyadmin_password: "{{ default_password }}"      # the password for the Ranger keyadmin user (will only be set in HDP3, in HDP2 it will remain the default keyadmin)
  kms_master_key_password: "{{ default_password }}"       # password used for encrypting the Master Key

##########################
## ambari configuration ##
##########################
# ambari_server
ambari_options:
  ambari_run_user: 'ambari'
  ambari_shell_password: 'ambari'
  ambari_admin_user: 'admin'
  ambari_admin_password: 'admin'
  ambari_admin_default_password: 'admin'                   # no need to change this (unless the Ambari default changes)
  config_recommendation_strategy: 'ALWAYS_APPLY'           # choose between 'NEVER_APPLY', 'ONLY_STACK_DEFAULTS_APPLY', 'ALWAYS_APPLY', 'ALWAYS_APPLY_DONT_OVERRIDE_CUSTOM_VALUES'

wait: true                                                 # wait for the cluster to finish installing
wait_timeout: 60
accept_gpl: yes                                            # set to yes to allow Ambari to install GPL licensed libraries

########################
## path configuration ##
########################
# Common base dirs
base_log_dir: "/var/log"
base_tmp_dir: "/tmp"

# Services base dirs
kafka_log_base_dir: "{% for dr in data_dirs %}{{ dr }}/kafka-logs{% if not loop.last %},{% endif %}{% endfor %}"
ams_base_dir: "/var/lib"
ranger_audit_hdfs_filespool_base_dir: "{{ base_log_dir }}"
ranger_audit_solr_filespool_base_dir: "{{ base_log_dir }}"

# HDFS main dirs
hdfs_dfs_namenode_checkpoint_dir: "{{ hadoop_base_dir }}/hdfs/namesecondary"
hdfs_dfs_namenode_name_dir: "{{ hadoop_base_dir }}/hdfs/namenode"        #one data dir
hdfs_dfs_journalnode_edits_dir: "{{ hadoop_base_dir }}/hdfs/journalnode" #one data dir
hdfs_dfs_datanode_data_dir: "{% for dr in data_dirs %}{{ dr }}/hadoop/hdfs/data{% if not loop.last %},{% endif %}{% endfor %}" #multiple data dir


# YARN main dirs
yarn_nodemanager_local_dirs: "{{ hadoop_base_dir }}/yarn/local"
yarn_nodemanager_log_dirs: "{{ hadoop_base_dir }}/yarn/log"
yarn_timeline_leveldb_dir: "{{ hadoop_base_dir }}/yarn/timeline"


# Other dirs
zookeeper_data_dir: "{{ hadoop_base_dir }}/zookeeper"
infra_solr_datadir: "{{ hadoop_base_dir }}/ambari-infra-solr/data"
heap_dump_location: "{{ base_tmp_dir }}"
hive_downloaded_resources_dir: "{{ base_tmp_dir }}/hive/${hive.session.id}_resources"
heap_dump_location: /tmp

stack_major_version: 3

ansible_tmp_dir: /tmp/ansible
ansible_options:
  ansible_ssh_port: 22



